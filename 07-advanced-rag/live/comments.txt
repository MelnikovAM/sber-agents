1. Первый эксперимент (Baseline)
Результаты Evaluation

📊 Датасет: 06-rag-qa-dataset
📝 Примеров обработано: 6

🎯 RAGAS Метрики:
🟡 Обоснованность (нет галлюцинаций): 0.778
🟡 Релевантность ответа: 0.759
🟡 Правильность ответа: 0.634
🟢 Похожесть на эталон: 0.912
🟢 Полнота контекста: 1.000
🟢 Точность поиска: 1.000

2. Эксперимент 2 - Hybrid Retrieval
Гипотеза: Добавление BM25 улучшит Context Recall, так как будет извлекаться больше релевантных документов.
Результаты Evaluation

📊 Датасет: 06-rag-qa-dataset
📝 Примеров обработано: 6

🎯 RAGAS Метрики:
🟢 Обоснованность (нет галлюцинаций): 0.849
🟡 Релевантность ответа: 0.766
🟢 Правильность ответа: 0.866
🟢 Похожесть на эталон: 0.934
🟢 Полнота контекста: 1.000
🟢 Точность поиска: 0.861

3. Эксперимент 3 - Hybrid + Reranker
Гипотеза: Cross-encoder reranking улучшит Context Precision за счет точной оценки релевантности.

📊 Датасет: 06-rag-qa-dataset
📝 Примеров обработано: 6

🎯 RAGAS Метрики:
🟢 Обоснованность (нет галлюцинаций): 0.917
🟡 Релевантность ответа: 0.765
🔴 Правильность ответа: 0.414
🟢 Похожесть на эталон: 0.907
🟢 Полнота контекста: 1.000
🟢 Точность поиска: 0.833

═══════════════════════════════════════════════════════════════════════
📈 АНАЛИЗ РЕЗУЛЬТАТОВ И ВЫВОДЫ
═══════════════════════════════════════════════════════════════════════

🏆 ЛУЧШИЙ РЕЖИМ: HYBRID RETRIEVAL (Эксперимент 2)

📊 Сравнительная таблица метрик:

                        Baseline    Hybrid      Hybrid+Reranker    Изменение
                        (Exp 1)     (Exp 2)     (Exp 3)            (Hybrid vs Baseline)
─────────────────────────────────────────────────────────────────────────────────────
Faithfulness            0.778       0.849       0.917              +9.1%  ⬆️
Answer Relevancy        0.759       0.766       0.765              +0.9%  ⬆️
Answer Correctness      0.634       0.866       0.414              +36.6% ⬆️⬆️⬆️
Answer Similarity       0.912       0.934       0.907              +2.4%  ⬆️
Context Recall          1.000       1.000       1.000              0%     ➡️
Context Precision       1.000       0.861       0.833              -13.9% ⬇️

═══════════════════════════════════════════════════════════════════════
🎯 ВЫВОДЫ ПО РЕЖИМАМ:
═══════════════════════════════════════════════════════════════════════

1️⃣ HYBRID показал лучшие результаты по ключевым метрикам:

   ✅ Answer Correctness (0.866) - лучший результат
      • Это самая важная метрика - правильность ответа
      • Улучшение на 36.6% по сравнению с baseline
      • Показывает, что ответы более точные и корректные

   ✅ Answer Similarity (0.934) - лучший результат
      • Ответы максимально похожи на эталонные
      • Улучшение на 2.4%

   ✅ Faithfulness (0.849) - хороший результат
      • Меньше галлюцинаций
      • Улучшение на 9.1%

   ⚠️ Context Precision (0.861) - небольшое снижение
      • Снизилась точность извлечения контекста на 13.9%
      • Причина: BM25 добавляет больше документов, некоторые менее релевантны
      • НО это компенсируется значительным ростом правильности ответов

═══════════════════════════════════════════════════════════════════════
💡 ПОЧЕМУ HYBRID ЛУЧШЕ?
═══════════════════════════════════════════════════════════════════════

🔍 Синергия двух подходов:
   • Semantic Search - находит документы по смыслу
   • BM25 - находит документы по точным терминам и ключевым словам
   • Вместе они покрывают больше типов запросов

📝 Особенно эффективно для:
   • Вопросов с конкретными терминами (названия продуктов, процентные ставки)
   • Вопросов со смысловыми синонимами
   • Комбинированных вопросов (термины + смысл)

🎯 Trade-off оправдан:
   • Небольшое снижение Context Precision (-13.9%)
   • За счет значительного роста Answer Correctness (+36.6%)
   • Итог: более правильные ответы важнее идеальной точности поиска

═══════════════════════════════════════════════════════════════════════
⚠️ ПОЧЕМУ HYBRID + RERANKER ПОКАЗАЛ ХУДШИЙ РЕЗУЛЬТАТ?
═══════════════════════════════════════════════════════════════════════

🔴 Answer Correctness упала до 0.414 (-65.5% от baseline)

Возможные причины:

1️⃣ Агрессивная фильтрация контекста:
   • Reranker отбирает только top-3 документа (RERANKER_TOP_K=3)
   • Hybrid извлекает 10+10=20 документов, reranker оставляет только 3
   • Может отфильтровать важную информацию для полного ответа

2️⃣ Модель cross-encoder не подходит для домена:
   • mmarco-mMiniLMv2-L12 обучена на общем корпусе
   • Банковская терминология может оцениваться некорректно

3️⃣ Конфликт с LLM:
   • LLM эффективнее работает с большим контекстом (10 документов)
   • Слишком агрессивная фильтрация лишает LLM возможности самостоятельно
     выбрать нужную информацию

═══════════════════════════════════════════════════════════════════════
🎖️ ИТОГОВЫЕ РЕКОМЕНДАЦИИ:
═══════════════════════════════════════════════════════════════════════

✅ ИСПОЛЬЗОВАТЬ: Hybrid Retrieval (Semantic + BM25)
   • Оптимальный баланс точности и полноты
   • +36.6% к правильности ответов
   • Подходит для production

❌ НЕ ИСПОЛЬЗОВАТЬ: Hybrid + Reranker (в текущей конфигурации)
   • Слишком агрессивная фильтрация вредит качеству
   • Если использовать reranker, нужно:
     - Увеличить RERANKER_TOP_K до 6-8
     - Попробовать другую модель cross-encoder для русского языка
     - Или использовать reranker только для сложных запросов

⚡ Возможные улучшения Hybrid режима:
   • Экспериментировать с весами ENSEMBLE (текущие: 0.5/0.5)
   • Попробовать разные значения K для semantic и BM25
   • A/B тестирование на большем датасете

═══════════════════════════════════════════════════════════════════════