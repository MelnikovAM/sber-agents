# Техническое видение проекта

## 1. Технологии

Минимальный стек для проверки идеи (MVP):

- Python (>=3.10)
- Управление зависимостями: uv (pyproject.toml)
- Сборка проекта и задачи: make
- LLM-клиент: openai python client (через Openrouter)
- Интеграция с Telegram Bot API: aiogram (метод polling)
- Документация: Markdown-файлы в директории docs/

## 2. Принцип разработки

- Только минимальный жизнеспособный продукт (MVP) — реализуем основной happy path.
- Все настройки — через конфиги и переменные окружения.
- Код сразу делим по функциям: Telegram-интерфейс, работа с LLM, бизнес-логика.
- Без тестов, CI/CD и прочих надстроек на этапе MVP.
- Минимум классов и абстракций: только функции и простые структуры.
- Асинхронный подход (async/await) для долгих операций.

## 3. Структура проекта

```
project_root/
│
├── bot/                # код инициализации и работы Telegram-бота
├── llm/                # модуль работы с OpenAI/Openrouter
├── config/             # хранение и чтение конфигов
├── main.py             # точка входа, минимальная сборка
├── Makefile            # задачи сборки и запуска
├── pyproject.toml      # зависимости (uv)
├── docs/               # документация проекта
└── README.md           # инструкция и запуск
```

- Каждый модуль — простейший набор функций или одна точка входа модуля, никаких избыточных абстракций.
- Только базовая структура для старта и быстрой доработки MVP.

## 4. Архитектура проекта

- **main.py** — минимальная точка входа, инициализация конфига и запуск бота.
- **bot/** — функции для подключения к Telegram, обработки сообщений, маршрутизации команд.
- **llm/** — функции для отправки промптов и получения ответов от LLM через Openrouter.
- **config/** — работа с переменными окружения и простейшими настройками.
- Логика работы: приём сообщения → запрос к LLM → ответ пользователю.
- Всё реализуется только простыми функциями, прямые вызовы между модулями.
- Нет БД, слоёв service/repository, очередей, middlewares и прочего — только необходимая логика работы MVP.

## 5. Модель данных

- Для каждого пользователя поддерживается элементарный in-memory-контекст (словарь на время жизни приложения):
    - Telegram user_id
    - Несколько последних сообщений и ответов (history)
- Вся работа — только с id пользователя Telegram и текстом сообщения.
- Операции с контекстом не влияют на логику вне основной цепочки "сообщение → контекст → LLM → ответ".
- Все токены и ключевые параметры — только через переменные окружения.
- Нет постоянного хранения, всё in-memory (при рестарте сбрасывается).

## 6. Работа с LLM

- Используется openai python client с endpoint провайдера Openrouter.
- Роль ассистента (системный промпт): "Персональный тренер по фитнесу".
- Для каждого запроса собирается история последних N сообщений пользователя и ответов (количество настраивается параметром).
- Название и версия модели OpenAI выбирается через параметр конфигурации.
- Потоковые ответы не используются, только полный текст.
- Все параметры интеграции (api-ключ, модель, history_len, url) задаются через переменные окружения или config.
- Ошибки от LLM обрабатываются дефолтно (показ пользователю сообщения "Ошибка, попробуйте позже"), детали не логируются.

## 7. Сценарии работы

- Пользователь пишет сообщение в Telegram-бот.
- Бот принимает сообщение, добавляет в in-memory history пользователя.
- Собирается короткий контекст последних N сообщений пользователя.
- Отправляется запрос к LLM (через Openrouter) с ролью "Персональный тренер по фитнесу".
- Ответ возвращается обратно пользователю в Telegram.
- В случае ошибки — краткое сообщение: "Ошибка, попробуйте позже".
- Помимо этого реализована поддержка /start — отправляется приветственное сообщение и краткая справка (описание доступных возможностей — просто напишите вопрос по своей фитнес-цели или тренировкам, и бот ответит как персональный тренер).

## 8. Подход к конфигурированию

- Все параметры и ключи (Telegram Bot Token, OpenRouter API Key, имя/версия модели, history_len и др.) задаются через переменные окружения.
- При старте приложения подключается python-dotenv (.env-файл).
- Все параметры читаются как строки из окружения, приведение к нужному типу (например, int для HISTORY_LEN) делается внутри кода.
- Перечень минимальных переменных:
    - TELEGRAM_BOT_TOKEN
    - OPENROUTER_API_KEY
    - OPENROUTER_MODEL (опционально)
    - OPENROUTER_URL (опционально)
    - HISTORY_LEN (опционально, дефолт например 3)
- Нет поддержки yaml/json-конфигов, только env/environment.

## 9. Подход к логгированию

- Используется стандартный logging из Python.
- Логируются только технические события: старт/остановка, ошибки, сбои, ключевые точки запуска.
- Не логируются пользовательские сообщения, запросы и ответы LLM.
- Уровень логирования по умолчанию — INFO, изменяется через переменную LOG_LEVEL.
- Логи выводятся и в stdout, и (если задано) в файл (путь задается через LOG_FILE).
- Ротация/архивация логов не реализуется, но возможно указать директорию для логов в переменной.
- Формат логов: [время][уровень] сообщение.

Пример:
```
[2025-11-09 21:00:00][INFO] Bot started (polling)
[2025-11-09 21:00:03][ERROR] LLM request failed: Timeout
```
